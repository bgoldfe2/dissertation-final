{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16501,"status":"ok","timestamp":1676067185646,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"},"user_tz":300},"id":"-gMWprA_zrAh","outputId":"036d36d9-2dd4-4c57-aafd-3339a83dd37b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Github\n"]}],"source":["# This is a new start using the Bangledesh team's most recent version of their codebase\n","# Starting the port to Google Drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/Github/"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"oWyJXCRE089U","executionInfo":{"status":"ok","timestamp":1676067189929,"user_tz":300,"elapsed":985,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}}},"outputs":[],"source":["!git config --global user.email \"bgoldfe2@gmu.edu\"\n","!git config --global user.name \"Bruce Goldfeder\"\n","!cp -R ssh ~/.ssh"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":112,"status":"ok","timestamp":1676067194926,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"},"user_tz":300},"id":"70JS5orH1ntq","outputId":"1a835695-5efa-4eb3-aa0c-542c5f5b5477"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Github/dissertation-final\n"]}],"source":["# %cd Extended-Cyberbullying-Detection/\n","%cd dissertation-final/"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":418,"status":"ok","timestamp":1676067198137,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"},"user_tz":300},"id":"6uPJRiqh1rNj","outputId":"42339cc1-2bec-40c2-af25-b793ef09a448"},"outputs":[{"output_type":"stream","name":"stdout","text":["total 40\n","drwx------ 2 root root 4096 Dec 27 18:26  Dataset\n","drwx------ 2 root root 4096 Dec 27 18:26  Figures\n","drwx------ 2 root root 4096 Jan 24 18:09  .git\n","-rw------- 1 root root  101 Jan 24 18:31  .gitignore\n","drwx------ 2 root root 4096 Dec 27 18:26  IPYNB\n","-rw------- 1 root root 1069 Jan 24 18:20  LICENSE\n","drwx------ 2 root root 4096 Dec 27 18:26  Models\n","drwx------ 2 root root 4096 Dec 27 18:26  Notebooks\n","drwx------ 2 root root 4096 Dec 27 18:26  Output\n","drwx------ 2 root root 4096 Dec 27 18:26 'Paper Figures'\n","-rw------- 1 root root  901 Feb 10 01:10  README.md\n","-rw------- 1 root root   45 Jan 24 18:20  requirements.txt\n","drwx------ 2 root root 4096 Dec 27 18:26  Scripts\n"]}],"source":["!ls -al"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14907,"status":"ok","timestamp":1676067223032,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"},"user_tz":300},"id":"cKgN_RP71trx","outputId":"48199004-9bbb-489c-f9e5-6f648ae83306"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (1.3.5)\n","Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 3)) (1.13.1+cu116)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (1.21.6)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers->-r requirements.txt (line 1)) (3.9.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers->-r requirements.txt (line 1)) (4.64.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers->-r requirements.txt (line 1)) (2022.6.2)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers->-r requirements.txt (line 1)) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers->-r requirements.txt (line 1)) (23.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers->-r requirements.txt (line 1)) (2.25.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->-r requirements.txt (line 2)) (2022.7.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->-r requirements.txt (line 3)) (4.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->-r requirements.txt (line 2)) (1.15.0)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (1.24.3)\n","Installing collected packages: tokenizers, sentencepiece, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.12.0 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.26.1\n"]}],"source":["!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1676067225099,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"},"user_tz":300},"id":"OjK_XOMDf-Mk","outputId":"571a57d7-a87b-4420-dda9-08e6749e1479"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Github/dissertation-final/Scripts\n"]}],"source":["%cd Scripts"]},{"cell_type":"code","source":["# Code block for running the evaluate and ensemble script\n","\n","#!python3 evaluate.py\n","\n","!python3 ensemble.py --ensemble_type rocauc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I-xZr9hP5iTf","executionInfo":{"status":"ok","timestamp":1675993995693,"user_tz":300,"elapsed":154071,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"bf48e9af-98a0-4ec2-d857-113a56caeb28"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-10 01:50:43.486413: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Downloading (…)solve/main/vocab.txt: 100% 232k/232k [00:00<00:00, 2.06MB/s]\n","Downloading (…)okenizer_config.json: 100% 28.0/28.0 [00:00<00:00, 10.8kB/s]\n","100% 299/299 [00:27<00:00, 10.93it/s]\n","Output length --- 9541, Prediction length --- 9541\n","ROC-AUC Score: 0.966572796483858\n","Downloading (…)ve/main/spiece.model: 100% 798k/798k [00:00<00:00, 6.72MB/s]\n","100% 299/299 [00:24<00:00, 12.02it/s]\n","Output length --- 9541, Prediction length --- 9541\n","ROC-AUC Score: 0.9771266459052416\n","Downloading (…)olve/main/vocab.json: 100% 899k/899k [00:00<00:00, 6.06MB/s]\n","Downloading (…)olve/main/merges.txt: 100% 456k/456k [00:00<00:00, 4.09MB/s]\n","100% 299/299 [00:28<00:00, 10.49it/s]\n","Output length --- 9541, Prediction length --- 9541\n","ROC-AUC Score: 0.9806770411835104\n","Downloading (…)solve/main/vocab.txt: 100% 232k/232k [00:00<00:00, 2.06MB/s]\n","Downloading (…)okenizer_config.json: 100% 28.0/28.0 [00:00<00:00, 10.5kB/s]\n","100% 299/299 [00:16<00:00, 17.73it/s]\n","Output length --- 9541, Prediction length --- 9541\n","ROC-AUC Score: 0.9717274344020341\n","Downloading (…)olve/main/vocab.json: 100% 1.04M/1.04M [00:00<00:00, 5.91MB/s]\n","Downloading (…)olve/main/merges.txt: 100% 456k/456k [00:00<00:00, 3.13MB/s]\n","100% 299/299 [00:30<00:00,  9.86it/s]\n","Output length --- 9541, Prediction length --- 9541\n","ROC-AUC Score: 0.9815385507222559\n"]}]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PDl54UWl3Sn6","outputId":"5f20ae19-be80-48aa-fc34-6956ad5fa617","executionInfo":{"status":"ok","timestamp":1676067369464,"user_tz":300,"elapsed":21488,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-10 22:15:51.031251: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-10 22:15:52.295239: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2023-02-10 22:15:52.295368: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2023-02-10 22:15:52.295392: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","{'Religion', 'Ethnicity', 'Others', 'Notcb', 'Gender', 'Age'}\n","train len - 28623, valid len - 9541, test len - 9541\n","Unnamed: 0\n","text\n","label\n","target\n","train example text --  If you call yourself a Christian yet you support this bill and the man pushing for it, you should be ashamed of yourself! Jesus Christ himself was radical during his time. And if he were here present today, he will be crucified again under this proposed law. #JUNKTERRORBILLNOW \n","with target --  Religion\n","Downloading (…)solve/main/vocab.txt: 100% 232k/232k [00:00<00:00, 2.96MB/s]\n","Downloading (…)okenizer_config.json: 100% 28.0/28.0 [00:00<00:00, 3.24kB/s]\n","Downloading (…)lve/main/config.json: 100% 483/483 [00:00<00:00, 153kB/s]\n","train_dataset object is of type --  <class 'dataset.DatasetDistilBert'>\n","Print Encoded Token Byte tensor at location 1 --  tensor([  101,  2065, 29337,  9289,  2135, 22957,  2884,  7011, 26654,  2937,\n","         6672,  3723,  3560,  6279,  6442, 15222, 19022,  9386, 26379, 28433,\n","        16275, 20668,  2075, 29278,  4183,  1010,  2017, 22231, 21285,  4783,\n","        11823, 14074,  3527, 12031, 22957,  2884,  2546,   999,  4441, 26654,\n","        14341, 11246,  2546, 17311, 12173,  7476, 24979,  2075, 24158,  7292,\n","         1012,  1998, 10128,  5369, 13777, 11106,  7869, 28994,  4765,  3406,\n","        10259,  1010,  2002, 29602, 20850,  8586,  6820,  6895, 10451, 16098,\n","         2378, 20824, 15222, 13102, 18981, 24768, 14919,  1012,  1001, 18015,\n","         3334, 29165, 24457, 19779,   102,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0])\n","The Decoded Token Text tensor is --  ['[CLS]', 'if', '##you', '##cal', '##ly', '##ours', '##el', '##fa', '##christ', '##ian', '##ye', '##ty', '##ous', '##up', '##port', '##thi', '##sb', '##illa', '##ndt', '##hema', '##np', '##ush', '##ing', '##for', '##it', ',', 'you', '##sho', '##uld', '##be', '##ash', '##ame', '##do', '##fy', '##ours', '##el', '##f', '!', 'jesus', '##christ', '##him', '##sel', '##f', '##was', '##rad', '##ical', '##dur', '##ing', '##his', '##time', '.', 'and', '##if', '##he', '##wer', '##eh', '##ere', '##pres', '##ent', '##to', '##day', ',', 'he', '##wil', '##lb', '##ec', '##ru', '##ci', '##fied', '##aga', '##in', '##under', '##thi', '##sp', '##rop', '##osed', '##law', '.', '#', 'junk', '##ter', '##ror', '##bill', '##now', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n","The model in the args is  distilbert-base-uncased\n","Downloading (…)\"pytorch_model.bin\";: 100% 268M/268M [00:02<00:00, 90.3MB/s]\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Model Class:  <class 'model.DistilBertFGBC'> Num Params:  66412614\n","<class 'list'>\n","(2,)\n","Traceback (most recent call last):\n","  File \"train.py\", line 213, in <module>\n","    run()\n","  File \"train.py\", line 111, in run\n","    asdf\n","NameError: name 'asdf' is not defined\n"]}],"source":["# Test run for regression testing\n","\n","!python3 train.py --epochs 1 --pretrained_model bert-base-uncased"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YlDjmLLxeoFE"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM1RmYb5HX0MttS1YF3t36s"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}