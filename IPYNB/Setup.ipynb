{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15359,"status":"ok","timestamp":1675992893039,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"},"user_tz":300},"id":"-gMWprA_zrAh","outputId":"55de1198-1bce-4c2c-cc18-5352eac55faa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Github\n"]}],"source":["# This is a new start using the Bangledesh team's most recent version of their codebase\n","# Starting the port to Google Drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/Github/"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"oWyJXCRE089U","executionInfo":{"status":"ok","timestamp":1675992898233,"user_tz":300,"elapsed":1031,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}}},"outputs":[],"source":["!git config --global user.email \"bgoldfe2@gmu.edu\"\n","!git config --global user.name \"Bruce Goldfeder\"\n","!cp -R ssh ~/.ssh"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":112,"status":"ok","timestamp":1675992911680,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"},"user_tz":300},"id":"70JS5orH1ntq","outputId":"d26f891e-aea6-4b13-a43d-fd5e53095df9"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Github/dissertation-final\n"]}],"source":["# %cd Extended-Cyberbullying-Detection/\n","%cd dissertation-final/"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":367,"status":"ok","timestamp":1675992917402,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"},"user_tz":300},"id":"6uPJRiqh1rNj","outputId":"7f7a9176-9b0c-4248-d476-9cf02364aa7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["total 40\n","drwx------ 2 root root 4096 Dec 27 18:26  Dataset\n","drwx------ 2 root root 4096 Dec 27 18:26  Figures\n","drwx------ 2 root root 4096 Jan 24 18:09  .git\n","-rw------- 1 root root  101 Jan 24 18:31  .gitignore\n","drwx------ 2 root root 4096 Dec 27 18:26  IPYNB\n","-rw------- 1 root root 1069 Jan 24 18:20  LICENSE\n","drwx------ 2 root root 4096 Dec 27 18:26  Models\n","drwx------ 2 root root 4096 Dec 27 18:26  Notebooks\n","drwx------ 2 root root 4096 Dec 27 18:26  Output\n","drwx------ 2 root root 4096 Dec 27 18:26 'Paper Figures'\n","-rw------- 1 root root  901 Feb 10 01:10  README.md\n","-rw------- 1 root root   45 Jan 24 18:20  requirements.txt\n","drwx------ 2 root root 4096 Dec 27 18:26  Scripts\n"]}],"source":["!ls -al"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10516,"status":"ok","timestamp":1675992931624,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"},"user_tz":300},"id":"cKgN_RP71trx","outputId":"38f095ed-0f53-4a80-cf7d-99ffa375b854"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (1.3.5)\n","Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 3)) (1.13.1+cu116)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (1.21.6)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers->-r requirements.txt (line 1)) (6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers->-r requirements.txt (line 1)) (4.64.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers->-r requirements.txt (line 1)) (23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers->-r requirements.txt (line 1)) (3.9.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers->-r requirements.txt (line 1)) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers->-r requirements.txt (line 1)) (2.25.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->-r requirements.txt (line 2)) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->-r requirements.txt (line 2)) (2.8.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->-r requirements.txt (line 3)) (4.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->-r requirements.txt (line 2)) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (1.24.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->-r requirements.txt (line 1)) (4.0.0)\n","Installing collected packages: tokenizers, sentencepiece, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.12.0 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.26.1\n"]}],"source":["!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":140,"status":"ok","timestamp":1675992936013,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"},"user_tz":300},"id":"OjK_XOMDf-Mk","outputId":"0252f561-422e-46cc-adb0-12de88bb5173"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Github/dissertation-final/Scripts\n"]}],"source":["%cd Scripts"]},{"cell_type":"code","source":["# Code block for running the evaluate and ensemble script\n","\n","#!python3 evaluate.py\n","\n","!python3 ensemble.py --ensemble_type rocauc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I-xZr9hP5iTf","executionInfo":{"status":"ok","timestamp":1675993995693,"user_tz":300,"elapsed":154071,"user":{"displayName":"Bruce Goldfeder","userId":"01568302622654738051"}},"outputId":"bf48e9af-98a0-4ec2-d857-113a56caeb28"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-10 01:50:43.486413: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Downloading (…)solve/main/vocab.txt: 100% 232k/232k [00:00<00:00, 2.06MB/s]\n","Downloading (…)okenizer_config.json: 100% 28.0/28.0 [00:00<00:00, 10.8kB/s]\n","100% 299/299 [00:27<00:00, 10.93it/s]\n","Output length --- 9541, Prediction length --- 9541\n","ROC-AUC Score: 0.966572796483858\n","Downloading (…)ve/main/spiece.model: 100% 798k/798k [00:00<00:00, 6.72MB/s]\n","100% 299/299 [00:24<00:00, 12.02it/s]\n","Output length --- 9541, Prediction length --- 9541\n","ROC-AUC Score: 0.9771266459052416\n","Downloading (…)olve/main/vocab.json: 100% 899k/899k [00:00<00:00, 6.06MB/s]\n","Downloading (…)olve/main/merges.txt: 100% 456k/456k [00:00<00:00, 4.09MB/s]\n","100% 299/299 [00:28<00:00, 10.49it/s]\n","Output length --- 9541, Prediction length --- 9541\n","ROC-AUC Score: 0.9806770411835104\n","Downloading (…)solve/main/vocab.txt: 100% 232k/232k [00:00<00:00, 2.06MB/s]\n","Downloading (…)okenizer_config.json: 100% 28.0/28.0 [00:00<00:00, 10.5kB/s]\n","100% 299/299 [00:16<00:00, 17.73it/s]\n","Output length --- 9541, Prediction length --- 9541\n","ROC-AUC Score: 0.9717274344020341\n","Downloading (…)olve/main/vocab.json: 100% 1.04M/1.04M [00:00<00:00, 5.91MB/s]\n","Downloading (…)olve/main/merges.txt: 100% 456k/456k [00:00<00:00, 3.13MB/s]\n","100% 299/299 [00:30<00:00,  9.86it/s]\n","Output length --- 9541, Prediction length --- 9541\n","ROC-AUC Score: 0.9815385507222559\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"PDl54UWl3Sn6","outputId":"cc0e1fc8-4614-4e0d-96a5-95286f4e22f5"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-01-21 22:04:38.594965: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","{'Ethnicity', 'Notcb', 'Religion', 'Others', 'Age', 'Gender'}\n","train len - 28623, valid len - 9541, test len - 9541\n","Downloading: 100% 232k/232k [00:00<00:00, 2.10MB/s]\n","Downloading: 100% 28.0/28.0 [00:00<00:00, 50.9kB/s]\n","Downloading: 100% 483/483 [00:00<00:00, 890kB/s]\n","The model in the args is  distilbert-base-uncased\n","Downloading: 100% 268M/268M [00:02<00:00, 95.6MB/s]\n","Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Model Parameter Count: 66412614\n","---Starting Training---\n","Epoch 1/10\n","----------\n","100% 1789/1789 [01:55<00:00, 15.53it/s, loss=1.15]\n","Epoch 1 --- Training loss: 1.1524794935230571 Training accuracy: 0.5474\n","100% 299/299 [00:16<00:00, 18.23it/s]\n","Epoch 1 --- Validation loss: 0.6662686432285053 Validation accuracy: 0.7474\n","Epoch 2/10\n","----------\n","100% 1789/1789 [01:54<00:00, 15.64it/s, loss=0.596]\n","Epoch 2 --- Training loss: 0.5961664859111779 Training accuracy: 0.7925\n","100% 299/299 [00:16<00:00, 17.92it/s]\n","Epoch 2 --- Validation loss: 0.5288967162271009 Validation accuracy: 0.8042\n","Epoch 3/10\n","----------\n","100% 1789/1789 [01:54<00:00, 15.67it/s, loss=0.477]\n","Epoch 3 --- Training loss: 0.47682688156191766 Training accuracy: 0.8356\n","100% 299/299 [00:16<00:00, 18.12it/s]\n","Epoch 3 --- Validation loss: 0.4929330033502451 Validation accuracy: 0.822\n","Epoch 4/10\n","----------\n","100% 1789/1789 [01:54<00:00, 15.61it/s, loss=0.38]\n","Epoch 4 --- Training loss: 0.3801166015386148 Training accuracy: 0.876\n","100% 299/299 [00:16<00:00, 18.18it/s]\n","Epoch 4 --- Validation loss: 0.49472642617680157 Validation accuracy: 0.8222\n","Epoch 5/10\n","----------\n","100% 1789/1789 [01:54<00:00, 15.67it/s, loss=0.305]\n","Epoch 5 --- Training loss: 0.3048305263135805 Training accuracy: 0.9052\n","100% 299/299 [00:16<00:00, 18.17it/s]\n","Epoch 5 --- Validation loss: 0.5234811501110278 Validation accuracy: 0.8219\n","Epoch 6/10\n","----------\n","100% 1789/1789 [01:54<00:00, 15.63it/s, loss=0.253]\n","Epoch 6 --- Training loss: 0.2527506097187088 Training accuracy: 0.9239\n","100% 299/299 [00:16<00:00, 18.03it/s]\n","Epoch 6 --- Validation loss: 0.6097163020019547 Validation accuracy: 0.8169\n","Epoch 7/10\n","----------\n","100% 1789/1789 [01:54<00:00, 15.64it/s, loss=0.215]\n","Epoch 7 --- Training loss: 0.21461698435800844 Training accuracy: 0.9368\n","100% 299/299 [00:16<00:00, 18.20it/s]\n","Epoch 7 --- Validation loss: 0.6350346667112714 Validation accuracy: 0.8151\n","Epoch 8/10\n","----------\n","100% 1789/1789 [01:54<00:00, 15.63it/s, loss=0.184]\n","Epoch 8 --- Training loss: 0.184414966950217 Training accuracy: 0.9462\n","100% 299/299 [00:16<00:00, 18.21it/s]\n","Epoch 8 --- Validation loss: 0.6525826848744349 Validation accuracy: 0.8159\n","Epoch 9/10\n","----------\n","100% 1789/1789 [01:55<00:00, 15.53it/s, loss=0.158]\n","Epoch 9 --- Training loss: 0.1581789896708417 Training accuracy: 0.953\n","100% 299/299 [00:16<00:00, 18.19it/s]\n","Epoch 9 --- Validation loss: 0.6987102383305397 Validation accuracy: 0.8142\n","Epoch 10/10\n","----------\n","100% 1789/1789 [01:54<00:00, 15.62it/s, loss=0.139]\n","Epoch 10 --- Training loss: 0.13944189502795676 Training accuracy: 0.9581\n","100% 299/299 [00:16<00:00, 18.11it/s]\n","Epoch 10 --- Validation loss: 0.7261669381356558 Validation accuracy: 0.8114\n","\n","---History---\n","defaultdict(<class 'list'>, {'train_acc': [0.5474, 0.7925, 0.8356, 0.876, 0.9052, 0.9239, 0.9368, 0.9462, 0.953, 0.9581], 'train_loss': [1.1524794935230571, 0.5961664859111779, 0.47682688156191766, 0.3801166015386148, 0.3048305263135805, 0.2527506097187088, 0.21461698435800844, 0.184414966950217, 0.1581789896708417, 0.13944189502795676], 'val_acc': [0.7474, 0.8042, 0.822, 0.8222, 0.8219, 0.8169, 0.8151, 0.8159, 0.8142, 0.8114], 'val_loss': [0.6662686432285053, 0.5288967162271009, 0.4929330033502451, 0.49472642617680157, 0.5234811501110278, 0.6097163020019547, 0.6350346667112714, 0.6525826848744349, 0.6987102383305397, 0.7261669381356558]})\n","##################################### Testing ############################################\n","\n","Evaluating: ---distilbert-base-uncased---\n","\n","100% 299/299 [00:16<00:00, 17.93it/s]\n","Output length --- 9541, Prediction length --- 9541\n","Accuracy: 0.8151137197358768\n","Mcc Score: 0.7782213737796172\n","Precision: 0.8151663194957193\n","Recall: 0.8151137197358768\n","F1_score: 0.814920043842779\n","classification_report:                precision    recall  f1-score   support\n","\n","           0     0.9126    0.9637    0.9375      1571\n","           1     0.9713    0.9401    0.9555      1586\n","           2     0.8572    0.8562    0.8567      1613\n","           3     0.5822    0.5631    0.5725      1584\n","           4     0.6195    0.6379    0.6285      1585\n","           5     0.9466    0.9288    0.9376      1602\n","\n","    accuracy                         0.8151      9541\n","   macro avg     0.8149    0.8150    0.8147      9541\n","weighted avg     0.8152    0.8151    0.8149      9541\n","\n","[[1514   10    6   19   11   11]\n"," [  38 1491   12   16   21    8]\n"," [  26    4 1381  104   89    9]\n"," [  34   12  104  892  492   50]\n"," [  13   14   94  447 1011    6]\n"," [  34    4   14   54    8 1488]]\n","ROC-AUC Score: 0.9717274344020341\n","##################################### Task End ############################################\n"]}],"source":["# Test run for regression testing\n","\n","!python3 train.py --split 'no' --epochs 10 --pretrained_model distilbert-base-uncased"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YlDjmLLxeoFE"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyO9LhYWH+6BocsXFSFWo8vU"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}